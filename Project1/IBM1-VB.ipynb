{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Model 1, Variational Bayes\n",
    "#### Authors: Adriaan de Vries, Féliciën Veldema, Verna Dankers\n",
    "\n",
    "This notebook implements the variational bayes training algorithm for IBM Model 1. Run the cells in order to run the algorithm.\n",
    "\n",
    "### 1. Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python libraries to install\n",
    "from __future__ import print_function, division\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "from random import random\n",
    "from scipy.special import digamma, loggamma, gammaln\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Custom requirements\n",
    "from aer import read_naacl_alignments, AERSufficientStatistics, test\n",
    "import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read in the data\n",
    "\n",
    "Please set the paths to the data and run the code below. Functions for reading in the data have been placed outside of the notebook, as they are re-used by other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the -UNK- token to the data.\n",
      "English data complete.\n",
      "French data complete\n",
      "Adding the -UNK- token to the data.\n",
      "English data complete.\n",
      "French data complete\n"
     ]
    }
   ],
   "source": [
    "english_train = 'training/hansards.36.2.e'\n",
    "french_train = 'training/hansards.36.2.f'\n",
    "english_val = 'validation/dev.e'\n",
    "french_val = 'validation/dev.f'\n",
    "fname = 'naacltest.txt'\n",
    "\n",
    "training_data = data.read_data(english_train, french_train, True)\n",
    "ext_data = list(zip(*training_data))\n",
    "validation_data = data.read_data(english_val, french_val, True, ttype='validation', eng_data=ext_data[0], fre_data=ext_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3. Implementation of IBM1 VB\n",
    "\n",
    "First, we implement the training algorithm, and the functions to calculate alignments, log likelihood and elbo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elbo(data, t, f_vocab, alpha, lambdas):\n",
    "    \"\"\"Calculate the ELBO for the training data.\n",
    "\n",
    "    Args:\n",
    "        data: zipped object with pairs of e and f sentences\n",
    "        t: dictionary with translation probabilities e to f\n",
    "        f_vocab: set of French words\n",
    "        alpha: value for dirichlet prior\n",
    "        lambdas: adapted counts from last iteration\n",
    "\n",
    "    Returns:\n",
    "        float: elbo\n",
    "    \"\"\"\n",
    "    # Start by calculating log likelihood\n",
    "    ll = log_likelihood(data, t)\n",
    "    \n",
    "    # Add -KL to the log likelihood\n",
    "    elbo = ll\n",
    "    gammaln_alpha = gammaln(alpha)\n",
    "    c = gammaln(alpha * len(f_vocab))\n",
    "    for e in tqdm(t):\n",
    "        a = sum([(math.log(t[e][f]) if t[e][f] != 0 else 0) * (alpha - lambdas[e][f])\n",
    "                 +  gammaln(lambdas[e][f]) - gammaln_alpha for f in lambdas[e] if f != \"-REST-\"])\n",
    "        b = gammaln(sum([(lambdas[e][f] if f in lambdas[e] else alpha) for f in f_vocab]))\n",
    "        elbo += a - b + c\n",
    "    return elbo\n",
    "\n",
    "def log_likelihood(data, translate_dict, add_constant=False):\n",
    "    \"\"\"Calculate the log likelihood for the training data.\n",
    "\n",
    "    Args:\n",
    "        data: zipped object with pairs of e and f sentences\n",
    "        translate_dict: dictionary with translation probabilities e to f\n",
    "        add_constant: whether to add the length normalisation constant\n",
    "\n",
    "    Returns:\n",
    "        float: log likelihood\n",
    "    \"\"\"\n",
    "    log_likelihood = 0\n",
    "    for e, f in data:\n",
    "        alignment = VB_align(e, f, translate_dict, True)\n",
    "        prob = 0\n",
    "        for j, i in alignment:\n",
    "            prob += math.log(translate_dict[e[j]][f[i-1]])\n",
    "        log_likelihood += prob\n",
    "\n",
    "        # Length normalisation constant\n",
    "        if add_constant:\n",
    "            log_likelihood += -len(f) * np.log(len(e) + 1)\n",
    "    return log_likelihood\n",
    "\n",
    "def initialize_t(data, uniform=True):\n",
    "    \"\"\"Initialise the translation probabilities.\n",
    "    \n",
    "    Args:\n",
    "        data: list of tuples, english and french sentences\n",
    "        uniform: boolean indicating initialisation type\n",
    "\n",
    "    Returns:\n",
    "        defaultdict(Counter)\n",
    "    \"\"\"\n",
    "    # Initialise random or uniform\n",
    "    t = defaultdict(Counter)\n",
    "    for e, f in tqdm(data):\n",
    "        for e_word in e:\n",
    "            for f_word in f:\n",
    "                if uniform:\n",
    "                    t[e_word][f_word] = 1\n",
    "                else:\n",
    "                    t[e_word][f_word] = random()\n",
    "\n",
    "    # Normalise counts for every English word\n",
    "    for e_word in t:\n",
    "        normalization_factor = sum(list(t[e_word].values()))\n",
    "        for f_word in t[e_word]:\n",
    "            t[e_word][f_word] = t[e_word][f_word] / normalization_factor\n",
    "    return t\n",
    "\n",
    "\n",
    "def VB_align(english_words, french_words, translate_dict, f_vocab, add_null=True):\n",
    "    \"\"\"Align one sentence pair, either with or without the NULL alignments.\n",
    "    \n",
    "    Args:\n",
    "        english_words: list of english words\n",
    "        french_words: list of french words\n",
    "        translate_dict: dictionary with translation probabilities e to f\n",
    "        add_null: boolean to indicate whether NULL alignments should be included\n",
    "\n",
    "    Return:\n",
    "        list of tuples\n",
    "    \"\"\"\n",
    "    alignment = []\n",
    "    for j, fword in enumerate(french_words):\n",
    "        prior = 0.0\n",
    "        alignment_j = 0\n",
    "        for i, eword in enumerate(english_words):\n",
    "            # Only include terms that are in the dictionary\n",
    "            if eword in translate_dict:\n",
    "                if fword in translate_dict[eword]:\n",
    "                    prob = translate_dict[eword][fword]\n",
    "                else:\n",
    "                    prob = translate_dict[eword][\"-REST-\"]\n",
    "                if prob > prior:\n",
    "                    prior = prob\n",
    "                    alignment_j = i\n",
    "                # Add dependent on whether it's a NULL alignments\n",
    "        if alignment_j != 0 or add_null:\n",
    "            alignment.append((alignment_j, j + 1))\n",
    "    return alignment\n",
    "\n",
    "def VB_align_all(data, translate_dict, f_vocab, fname=None):\n",
    "    \"\"\"Create alignments for pairs of English and French sentences.\n",
    "    Both save them as sets per sentence and pair and save to file.\n",
    "    \n",
    "    Args:\n",
    "        validation: zipped object with pairs of e and f sentences\n",
    "        translate_dict: dictionary with translation probabilities e to f\n",
    "        fname: filename to save alignments in, in NAACL format\n",
    "\n",
    "    Returns:\n",
    "        list of sets\n",
    "    \"\"\"\n",
    "    file = open(fname, 'w')\n",
    "    alignments = []\n",
    "    for k, (english_words, french_words) in enumerate(data):\n",
    "        alignment = VB_align(english_words, french_words, translate_dict, f_vocab, False)\n",
    "        for pos1, pos2 in alignment:\n",
    "            file.write(\"{} {} {}\\n\".format(str(k+1), str(pos1), str(pos2)))\n",
    "        alignments.append(set(alignment))\n",
    "    return alignments\n",
    "\n",
    "def VB_IBM1(data, validation, alpha, max_steps=20, translate_dict=None):\n",
    "    print(\"Initializing translation dictionary.\")\n",
    "    if translate_dict is None:\n",
    "        translate_dict = initialize_t(data)\n",
    "    e_vocab = translate_dict.keys()\n",
    "    f_vocab = {f for e in translate_dict for f in translate_dict[e]}\n",
    "    for iteration in range(max_steps):\n",
    "        change = False\n",
    "        fname = 'iteration' + str(iteration) + '.txt'\n",
    "        lambdas = defaultdict(lambda : defaultdict(lambda : alpha))\n",
    "\n",
    "        print(\"Expectation step {}\".format(iteration + 1))\n",
    "        for e_s, f_s in tqdm(data):\n",
    "            for f in f_s:\n",
    "                sum_of_probs = sum([translate_dict[e2][f] for e2 in e_s])\n",
    "                for e in e_s:\n",
    "                    lambdas[e][f] += translate_dict[e][f] / sum_of_probs\n",
    "\n",
    "        print(\"Maximisation step {}\".format(iteration + 1))\n",
    "        for e in tqdm(e_vocab):\n",
    "            summation = 0\n",
    "            for f2 in f_vocab:\n",
    "                if f2 in lambdas[e]:\n",
    "                    summation += lambdas[e][f2]\n",
    "                else:\n",
    "                    summation += alpha\n",
    "            summation = digamma(summation)\n",
    "            for f in translate_dict[e]:\n",
    "                translate_dict[e][f] = np.exp(digamma(lambdas[e][f]) - summation)\n",
    "            translate_dict[e][\"-REST-\"] = np.exp(digamma(alpha) - summation)\n",
    "\n",
    "        alignments = VB_align_all(validation, translate_dict, f_vocab, fname)\n",
    "        eb = elbo(data, translate_dict, f_vocab, alpha, lambdas)\n",
    "        print(\"Elbo: {}\".format(eb))\n",
    "        aer = test(\"\", alignments)\n",
    "        print(\"AER: {}\".format(aer))\n",
    "        # pickle.dump(translate_dict, open(\"translate_dicts/ibm1_vb_epoch_{}.pickle\".format(iteration + 1), 'wb'))\n",
    "    return translate_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4. Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing translation dictionary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 231164/231164 [00:50<00:00, 4561.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expectation step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 231164/231164 [02:31<00:00, 1523.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximisation step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 25593/25593 [04:12<00:00, 101.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-17573799.8262083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 25593/25593 [04:05<00:00, 104.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo: -62703128.3598518\n",
      "AER: 0.3697718631178707\n",
      "Expectation step 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 231164/231164 [03:37<00:00, 1063.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximisation step 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:38<00:00, 75.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12053928.908525312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:30<00:00, 77.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo: -25999655.36870337\n",
      "AER: 0.3378509196515005\n",
      "Expectation step 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 231164/231164 [03:27<00:00, 1113.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximisation step 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:48<00:00, 73.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10373936.71996149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [06:02<00:00, 70.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo: -15908872.020047462\n",
      "AER: 0.32748538011695905\n",
      "Expectation step 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 231164/231164 [04:01<00:00, 957.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximisation step 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [06:38<00:00, 64.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9551558.112916136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:29<00:00, 77.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo: -13279577.700044598\n",
      "AER: 0.3195266272189349\n",
      "Expectation step 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 231164/231164 [03:19<00:00, 1159.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximisation step 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:47<00:00, 73.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9069730.165113095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [06:08<00:00, 69.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo: -12195409.232732926\n",
      "AER: 0.3168805528134254\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.0005\n",
    "translate_dict = VB_IBM1(training_data, validation_data, alpha, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing translation dictionary.\n",
      "Expectation step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 231164/231164 [03:25<00:00, 1125.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximisation step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:57<00:00, 71.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8756675.05166398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:49<00:00, 73.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo: -11604593.752000997\n",
      "AER: 0.3165182987141444\n",
      "Expectation step 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 231164/231164 [03:43<00:00, 1034.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximisation step 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [06:00<00:00, 70.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8538643.967889402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [06:12<00:00, 68.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo: -11233624.917231584\n",
      "AER: 0.3214638971315529\n",
      "Expectation step 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 231164/231164 [03:27<00:00, 1114.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximisation step 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:53<00:00, 72.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8379600.277170806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [06:22<00:00, 66.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo: -10979227.661674405\n",
      "AER: 0.3204747774480712\n",
      "Expectation step 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 231164/231164 [03:20<00:00, 1155.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximisation step 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:42<00:00, 74.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8260401.581531495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:31<00:00, 77.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo: -10795209.766810227\n",
      "AER: 0.32015810276679846\n",
      "Expectation step 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 231164/231164 [03:13<00:00, 1195.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximisation step 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:41<00:00, 75.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8168587.427075919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:46<00:00, 73.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo: -10657075.245848164\n",
      "AER: 0.3184965380811078\n",
      "Expectation step 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 231164/231164 [03:11<00:00, 1205.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximisation step 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:38<00:00, 75.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8096092.05062316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:32<00:00, 76.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo: -10550704.063032232\n",
      "AER: 0.3175074183976261\n",
      "Expectation step 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 231164/231164 [03:13<00:00, 1197.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximisation step 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:45<00:00, 74.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8037669.674119085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [06:17<00:00, 67.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo: -10465662.038439553\n",
      "AER: 0.3177290836653387\n",
      "Expectation step 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 231164/231164 [03:12<00:00, 1202.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximisation step 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:37<00:00, 75.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7989495.226116224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:54<00:00, 72.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo: -10396671.125520742\n",
      "AER: 0.31200000000000006\n",
      "Expectation step 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 231164/231164 [03:11<00:00, 1209.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximisation step 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:36<00:00, 76.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7949260.621093685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [06:04<00:00, 70.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo: -10339764.700858975\n",
      "AER: 0.31299999999999994\n",
      "Expectation step 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 231164/231164 [03:11<00:00, 1205.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximisation step 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:38<00:00, 75.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7915413.05314147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 25593/25593 [05:31<00:00, 77.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo: -10292240.937078912\n",
      "AER: 0.31299999999999994\n"
     ]
    }
   ],
   "source": [
    "translate_dict2 = VB_IBM1(training_data, validation_data, alpha, 10, translate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
